{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012579,"end_time":"2024-07-23T15:38:45.674249","exception":false,"start_time":"2024-07-23T15:38:45.66167","status":"completed"},"tags":[]},"source":["# What is about ?\n","\n","### Brief \n","\n","(c) Alexander Chervov, Kirill Khoruzhii\n","\n","Beam search for graphs (Cayley graphs of the permutation groups) basic simple tutorial version.\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Beam search function "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:59:51.095394Z","iopub.status.busy":"2024-09-04T20:59:51.095043Z","iopub.status.idle":"2024-09-04T20:59:55.897247Z","shell.execute_reply":"2024-09-04T20:59:55.896301Z","shell.execute_reply.started":"2024-09-04T20:59:51.095364Z"},"papermill":{"duration":0.062823,"end_time":"2024-07-23T15:40:22.716754","exception":false,"start_time":"2024-07-23T15:40:22.653931","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","6.556510925292969e-05 hash\n","6.890296936035156e-05 sort\n","0.0001518726348876953 mask\n","\n","Search finished. beam_width: 2\n","1  steps to destination state. Path found.\n","cuda\n","2.5510787963867188e-05 hash\n","4.839897155761719e-05 sort\n","8.392333984375e-05 mask\n","2.3126602172851562e-05 hash\n","4.172325134277344e-05 sort\n","7.009506225585938e-05 mask\n","2.2172927856445312e-05 hash\n","3.886222839355469e-05 sort\n","0.00012540817260742188 mask\n","\n","Search finished. beam_width: 2\n","3  steps to destination state. Path found.\n","CPU times: user 4.47 ms, sys: 20.6 ms, total: 25 ms\n","Wall time: 23.8 ms\n"]}],"source":["%%time\n","import numpy as np\n","import pandas as pd\n","import time\n","import torch\n","\n","def beam_search_permutations_torch(\n","    state_start = [2,1,0],\n","    generators = [[0,1,2],[0,2,1]],\n","    models_or_heuristics  = 'Hamming',\n","    beam_width = 2,\n","    state_destination = '01234...',\n","    n_steps_limit = 100,\n","    dtype = 'Auto',\n","    vec_hasher = 'Auto',\n","    verbose = 0,\n","):\n","    '''\n","    Find path from the \"state_start\" to the \"state_destination\" via beam search.\n","\n","    Main parameters:\n","        state_start - state to be solved, i.e. from where we need to find path to the destination\n","        generators - generators of the group\n","        beam_width - beam width\n","        state_destination = '01234...' - destination state, typically 0,1,2,3,... - identity permutation\n","        models_or_heuristics - machine learning model or name for hearistical metric\n","        n_step_max - maximal number of steps to try\n","    Technical parameters:\n","        vec_hasher - vector used for hashing\n","        dtype      - dtype for states\n","        verbose    - contols how many text output during the exection\n","    '''\n","\n","    ####################################################################################\n","    # Analyse input params and convert to stadard forms\n","    ####################################################################################\n","    # generators_type = 'permutation' # 'matrix'\n","\n","    # device\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","    else:\n","        device = torch.device(\"cpu\")\n","    print(device)\n","\n","    # Analyse input format of \"generators\"\n","    # can be list_generators, or tensor/np.array with rows - generators\n","    if isinstance(generators, list):\n","        list_generators = generators\n","    elif isinstance(generators, torch.Tensor ):\n","        list_generators = [ list(generators[i,:]) for i in range(generators.shape[0] ) ]\n","    elif isinstance(generators, np.ndarray ):\n","        list_generators = [list(generators[i,:]) for i in range(generators.shape[0] ) ]\n","    else:\n","        print('Unsupported format for \"generators\"', type(generators), generators)\n","        raise ValueError('Unsupported format for \"generators\" ' + str(type(generators)) )\n","    state_size = len(list_generators[0])\n","    tensor_all_generators = torch.tensor( list_generators , device = device, dtype = torch.int64)\n","\n","    # dtype\n","    if dtype == 'Auto':\n","        if state_size <= 256:\n","            dtype = torch.uint8\n","        else:\n","            dtype = torch.uint16\n","\n","    # Destination state\n","    if state_destination == '01234...':\n","        state_destination = torch.arange( state_size, device=device, dtype = dtype).reshape(-1,state_size)\n","    elif isinstance(state_destination, torch.Tensor ):\n","        state_destination =  state_destination.to(device).to(dtype).reshape(-1,state_size)\n","    else:\n","        state_destination = torch.tensor( state_destination, device=device, dtype = dtype).reshape(-1,state_size)\n","\n","    # state_start\n","    if isinstance(state_start, torch.Tensor ):\n","        state_start =  state_start.to(device).to(dtype).reshape(-1,state_size)\n","    else:\n","        state_start = torch.tensor( state_start, device=device, dtype = dtype).reshape(-1,state_size)\n","\n","    # Vec_hasher\n","    dtype_for_hash = torch.int64\n","    if vec_hasher == 'Auto':\n","        # Hash vector generation\n","        max_int =  int( (2**62) )     #print(max_int)\n","        vec_hasher = torch.randint(-max_int, max_int,   size= (state_size,),  device=device, dtype = dtype_for_hash) #\n","    elif not isinstance( vec_hasher , torch.Tensor):\n","        vec_hasher = torch.tensor( vec_hasher , device=device, dtype = dtype_for_hash )\n","    else:\n","        vec_hasher = vec_hasher.to(device).to(dtype_for_hash)\n","\n","\n","    ##########################################################################################\n","    # Initializations\n","    ##########################################################################################\n","\n","    # Initialize array of states\n","    array_of_states = state_start.view(-1, state_size  ).clone().to(dtype).to(device)\n","\n","    ##########################################################################################\n","    # Main Loop over steps\n","    ##########################################################################################\n","    for i_step in range(1,n_steps_limit+1):\n","\n","        # Apply generator to all current states\n","        array_of_states_new = get_neighbors(array_of_states,tensor_all_generators.to(torch.int64) ).flatten(end_dim=1)\n","\n","        # Take only unique states\n","        # surprise: THAT IS CRITICAL for beam search performance !!!!\n","        # if that is not done - beam search  will not find the desired state - quite often\n","        # The reason - essentianlly beam can degrade, i.e. can be populated by copy of only one state\n","        # It is surprising that such degradation  happens quite often even for beam_width = 10_000 - but it is indeed so\n","        array_of_states_new = get_unique_states_2(array_of_states_new, vec_hasher)\n","\n","        # Check destination state found\n","        vec_tmp = torch.all(array_of_states_new == state_destination, axis =1) # Compare state_destination and each row array_of_states\n","        flag_found_destination = torch.any(vec_tmp).item() # Check for coincidence\n","        if (flag_found_destination) :\n","            if (verbose >= 10 ):\n","                print('Found destination state. ', 'i_step:', i_step, ' n_ways:', (vec_tmp).sum())\n","            break\n","\n","        # Estimate distance of new states to the destination state (or best moves probabilities for policy models)\n","        if array_of_states_new.shape[0] > beam_width: # If we have not so many states - we take them all - no need for ML-model\n","            if models_or_heuristics == 'Hamming':\n","                estimations_for_new_states = torch.sum( (array_of_states_new == state_destination[0,:]) , dim = 1)\n","            else:\n","                raise ValueError('Unsupported models_or_heauristics ' + str(models_or_heauristics) )\n","\n","            # Take only \"beam_width\" of the best states (i.e. most nearest to destination according to the model estimate)\n","            idx = torch.argsort(estimations_for_new_states)[:beam_width]\n","            array_of_states = array_of_states_new[idx,:]\n","\n","        else:\n","            # If number of states is less than beam_width - we take them all:\n","            array_of_states = array_of_states_new\n","\n","\n","        if verbose >= 10:\n","            print(i_step,'i_step', array_of_states_new.shape, 'array_of_states_new.shape' )\n","\n","    dict_additional_data = {}\n","    if verbose >= 1:\n","        print();\n","        print('Search finished.', 'beam_width:', beam_width)\n","        if flag_found_destination:\n","            print(i_step, ' steps to destination state. Path found.')\n","        else:\n","            print('Path not found.')\n","\n","    return flag_found_destination, i_step, dict_additional_data\n","\n","\n","def get_unique_states_2(states: torch.Tensor, vec_hasher : torch.Tensor) -> torch.Tensor:\n","    '''\n","    Return matrix with unique rows for input matrix \"states\"\n","    I.e. duplicate rows are dropped.\n","    For fast implementation: we use hashing via scalar/dot product.\n","    Note: output order of rows is different from the original.\n","    '''\n","    # Note: that implementation is 30 times faster than torch.unique(states, dim = 0) - because we use hashes  (see K.Khoruzhii: https://t.me/sberlogasci/10989/15920)\n","    # Note: torch.unique does not support returning of indices of unique element so we cannot use it\n","    # That is in contrast to numpy.unique which supports - set: return_index = True\n","\n","    device = states.device\n","\n","    t1 = time.time()\n","    # Hashing rows of states matrix:\n","    hashed = torch.sum( states * vec_hasher.to(device), dim=1) # Compute hashes.\n","        # It is same as matrix product torch.matmul(hash_vec , states )\n","        # but pay attention: such code work with GPU for integers\n","        # While torch.matmul - does not work for GPU for integer data types,\n","        # since old GPU hardware (before 2020: P100, T4) does not support integer matrix multiplication\n","    t1 = time.time() - t1\n","    print(t1,'hash')\n","\n","    # Sort\n","    t1 = time.time()\n","    hashed_sorted, idx = torch.sort(hashed)\n","    t1 = time.time() - t1\n","    print(t1,'sort')\n","\n","    # Mask selects elements which are different from the consequite - that is unique elements (since vector is sorted on the previous step)\n","    t1 = time.time()\n","    mask = torch.concat((torch.tensor([True], device = device), hashed_sorted[1:] - hashed_sorted[:-1] > 0))\n","    t1 = time.time() - t1\n","    print(t1,'mask')\n","    return states[idx][mask]\n","\n","def get_neighbors(states, moves):\n","    \"\"\"\n","    Some torch magic to calculate all new states which can be obtained from states by moves\n","    \"\"\"\n","    return torch.gather(\n","        states.unsqueeze(1).expand(states.size(0), moves.shape[0], states.size(1)),\n","        2,\n","        moves.unsqueeze(0).expand(states.size(0), moves.shape[0], states.size(1)))\n","\n","flag_found_destination, i_step, dict_additional_data  =\\\n","    beam_search_permutations_torch(state_start = [1,0], generators = [[1,0]], verbose = 1 )\n","flag_found_destination, i_step, dict_additional_data  =\\\n","    beam_search_permutations_torch(state_start = [2,1,0], generators = [[1,0,2],[0,2,1]] , verbose = 1)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Benchmarks"]},{"cell_type":"markdown","metadata":{},"source":["## Preparations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:16:41.394489Z","iopub.status.busy":"2024-09-04T20:16:41.394144Z","iopub.status.idle":"2024-09-04T20:16:41.426061Z","shell.execute_reply":"2024-09-04T20:16:41.425095Z","shell.execute_reply.started":"2024-09-04T20:16:41.394463Z"},"papermill":{"duration":0.061004,"end_time":"2024-07-23T16:07:40.509017","exception":false,"start_time":"2024-07-23T16:07:40.448013","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["list_generators_cube333_12gensQTM = [[6, 3, 0, 7, 4, 1, 8, 5, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 47, 21, 22, 50, 24, 25, 53, 27, 28, 38, 30, 31, 41, 33, 34, 44, 36, 37, 20, 39, 40, 23, 42, 43, 26, 45, 46, 29, 48, 49, 32, 51, 52, 35], [0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 12, 9, 16, 13, 10, 17, 14, 11, 36, 19, 20, 39, 22, 23, 42, 25, 26, 45, 28, 29, 48, 31, 32, 51, 34, 35, 27, 37, 38, 30, 40, 41, 33, 43, 44, 18, 46, 47, 21, 49, 50, 24, 52, 53], [44, 43, 42, 3, 4, 5, 6, 7, 8, 45, 46, 47, 12, 13, 14, 15, 16, 17, 24, 21, 18, 25, 22, 19, 26, 23, 20, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 11, 10, 9, 0, 1, 2, 48, 49, 50, 51, 52, 53], [0, 1, 2, 3, 4, 5, 51, 52, 53, 9, 10, 11, 12, 13, 14, 38, 37, 36, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 30, 27, 34, 31, 28, 35, 32, 29, 8, 7, 6, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 15, 16, 17], [0, 1, 35, 3, 4, 34, 6, 7, 33, 20, 10, 11, 19, 13, 14, 18, 16, 17, 2, 5, 8, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 9, 12, 15, 42, 39, 36, 43, 40, 37, 44, 41, 38, 45, 46, 47, 48, 49, 50, 51, 52, 53], [24, 1, 2, 25, 4, 5, 26, 7, 8, 9, 10, 27, 12, 13, 28, 15, 16, 29, 18, 19, 20, 21, 22, 23, 17, 14, 11, 6, 3, 0, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 51, 48, 45, 52, 49, 46, 53, 50, 47], [2, 5, 8, 1, 4, 7, 0, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 38, 21, 22, 41, 24, 25, 44, 27, 28, 47, 30, 31, 50, 33, 34, 53, 36, 37, 29, 39, 40, 32, 42, 43, 35, 45, 46, 20, 48, 49, 23, 51, 52, 26], [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 14, 17, 10, 13, 16, 9, 12, 15, 45, 19, 20, 48, 22, 23, 51, 25, 26, 36, 28, 29, 39, 31, 32, 42, 34, 35, 18, 37, 38, 21, 40, 41, 24, 43, 44, 27, 46, 47, 30, 49, 50, 33, 52, 53], [45, 46, 47, 3, 4, 5, 6, 7, 8, 44, 43, 42, 12, 13, 14, 15, 16, 17, 20, 23, 26, 19, 22, 25, 18, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 2, 1, 0, 9, 10, 11, 48, 49, 50, 51, 52, 53], [0, 1, 2, 3, 4, 5, 38, 37, 36, 9, 10, 11, 12, 13, 14, 51, 52, 53, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32, 35, 28, 31, 34, 27, 30, 33, 17, 16, 15, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 6, 7, 8], [0, 1, 18, 3, 4, 19, 6, 7, 20, 33, 10, 11, 34, 13, 14, 35, 16, 17, 15, 12, 9, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 8, 5, 2, 38, 41, 44, 37, 40, 43, 36, 39, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53], [29, 1, 2, 28, 4, 5, 27, 7, 8, 9, 10, 26, 12, 13, 25, 15, 16, 24, 18, 19, 20, 21, 22, 23, 0, 3, 6, 11, 14, 17, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 50, 53, 46, 49, 52, 45, 48, 51]]\n","\n","\n","def scramble_given_state(list_generators, n_scrambles,    state_to_scramble  = '01234...'   ):\n","    if state_to_scramble == '01234...':\n","        state_size = len( list_generators[0] )\n","        state_to_scramble = np.arange(state_size)\n","    state_current = state_to_scramble\n","    if isinstance(state_current,list):\n","        state_current = np.asarray(state_current)\n","    elif isinstance(state_current,range):\n","        state_current = np.asarray(state_current)\n","    n_gens = len(list_generators)\n","    for k in range(n_scrambles):\n","        IX_move = np.random.randint(0, n_gens, dtype = int) # random moves indixes\n","        state_current = state_current[ list_generators[IX_move]] # all_moves[IX_moves,:] ]\n","    return state_current\n","\n","print( scramble_given_state( list_generators_cube333_12gensQTM, 0, ) )\n","print( scramble_given_state( list_generators_cube333_12gensQTM, 10) )\n"]},{"cell_type":"markdown","metadata":{},"source":["# Main plot - probabilities to find solution by beam search depending on number of scrambles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T20:18:23.946989Z","iopub.status.busy":"2024-09-04T20:18:23.946034Z","iopub.status.idle":"2024-09-04T20:21:50.670788Z","shell.execute_reply":"2024-09-04T20:21:50.669845Z","shell.execute_reply.started":"2024-09-04T20:18:23.946954Z"},"trusted":true},"outputs":[],"source":["%%time\n","# n_scrambles_starting_state = 1000\n","# print('n_scrambles_starting_state:',n_scrambles_starting_state)\n","\n","verbose = 0\n","n_trials = 100\n","list_n_scrambles = list(range(1,16))\n","\n","\n","import matplotlib.pyplot as plt\n","list_generators = list_generators_cube333_12gensQTM\n","\n","fig = plt.figure(figsize = (20,8))\n","\n","for beam_width in [1, 10 ,100,1000,10_000,100_000]:\n","\n","    str_inf = 'Cube333QTM Hamming + beam_width ' + str(beam_width)\n","    if verbose >= 1:\n","        print(str_inf, 'n_trials:', n_trials)\n","\n","    df_stat = pd.DataFrame()\n","\n","    for i_trial in range(n_trials):\n","        if i_trial < 25:\n","            #print()\n","            if verbose>=10:\n","                print('trial:', i_trial)\n","        # destination state - \"solved puzzle state\"\n","        state_size = len( list_generators[0])\n","        #state_destination = torch.arange( state_size, device=device, dtype = dtype)\n","        state_destination = range(state_size)\n","\n","        #state_start\n","\n","        prm_name = 'n_scramble '\n","        list_prm_value = list_n_scrambles# list(range(1,15))\n","        for prm_value in list_prm_value:#  5_000,10_000, 30_000]:#, 100_000]:\n","            n_scrambles_starting_state = prm_value\n","\n","            # Scramble - generate state which will be start of beam search\n","            state_start = state_destination\n","            state_start = scramble_given_state( list_generators, n_scrambles_starting_state, state_start )\n","\n","            # Beam search\n","            t0 = time.time()\n","            flag_found_destination, i_step, dict_additional_data  =\\\n","                beam_search_permutations_torch(state_start = state_start, generators = list_generators,\n","                    beam_width = beam_width,\n","                    models_or_heuristics  = 'Hamming'     ,\n","                    state_destination = '01234...'  ,\n","                    n_steps_limit = 100 ,\n","                    verbose = 0)\n","\n","            if i_trial < 1:\n","                if verbose >=10:\n","                    print('Found:',flag_found_destination,'steps:', i_step,'beam_width:', beam_width,\n","                          'time: %.1f secs'%(time.time()-t0))\n","\n","            df_stat.loc[i_trial,'Path length.  '+prm_name+str(prm_value)] =  i_step\n","            df_stat.loc[i_trial,'Solution found. '+prm_name +str(prm_value)] =  int(flag_found_destination)\n","            df_stat.loc[i_trial,'Time. '+prm_name+str(prm_value)] =  np.round(time.time()-t0,1)\n","\n","    df_stat.to_csv('stat_beam_search_'+prm_name+'_'+str_inf+'.csv')\n","    if verbose >=10:\n","        display(df_stat)\n","        display(df_stat.describe().round(3).T)\n","        display(df_stat.describe().round(3).to_csv('aggregated_stat_beam_search_'+prm_name+'_'+str_inf+'.csv'))\n","\n","\n","    df_loc = df_stat.describe()\n","    dat_loc = []\n","\n","    col_key = 'Solution found'\n","    for col in df_stat.columns:\n","        if not( col_key in col) : continue\n","        dat_loc.append(df_loc.loc['mean', col] )\n","\n","    plt.plot(list_prm_value, dat_loc, '*-',label = str_inf)\n","    #plt.title(col_key , fontsize = 20  )\n","    plt.title('Probability to find solution by beam search' , fontsize = 20  )\n","    plt.ylabel('probability to find solution', fontsize = 20 )\n","    plt.xlabel('n_scrambles', fontsize = 20 )\n","    plt.xticks(list_prm_value, list_prm_value)\n","    plt.legend(fontsize = 20 )\n","    plt.savefig(col_key.replace('.', ' ') + '.png')\n","\n","\n","\n","plt.grid()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4441442,"sourceId":8629066,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1739.866157,"end_time":"2024-07-23T16:07:42.769562","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-23T15:38:42.903405","version":"2.5.0"}},"nbformat":4,"nbformat_minor":4}
